<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChangeListManager">
    <list default="true" id="359a81d1-a1e5-4eac-91a2-6b13a25942df" name="Default Changelist" comment="">
      <change afterPath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/Dockerfile" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/requirements.txt" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo" beforeDir="false" afterPath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/middlewares.py" beforeDir="false" afterPath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/middlewares.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/spiders/weibocn.py" beforeDir="false" afterPath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/spiders/weibocn.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial" beforeDir="false" afterPath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.csv" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.jl" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.json" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.jsonlines" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.marshal" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.pickle" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.xml" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/settings.py" beforeDir="false" afterPath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/settings.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/spiders/quotes.py" beforeDir="false" afterPath="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/spiders/quotes.py" afterDir="false" />
    </list>
    <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="CoverageDataManager">
    <SUITE FILE_PATH="coverage/PythonStudy$01___2_.coverage" NAME="01-读取文件 (2) Coverage Results" MODIFIED="1534240990207" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-10/01-read-file" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_requestspost.coverage" NAME="04-requests提交post请求 Coverage Results" MODIFIED="1534757964086" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_Ajax.coverage" NAME="01-Ajax获取马云的所有微博 Coverage Results" MODIFIED="1535004937823" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section6-Ajax" />
    <SUITE FILE_PATH="coverage/PythonStudy$06_test_.coverage" NAME="06-解析test网页-属性获取 Coverage Results" MODIFIED="1534840583743" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/01-XPath的使用" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_ID.coverage" NAME="03-获取ID、位置、标签名、大小 Coverage Results" MODIFIED="1535012090922" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/05-获取节点信息" />
    <SUITE FILE_PATH="coverage/PythonStudy$03___1_.coverage" NAME="03-抓取二进制数据 (1) Coverage Results" MODIFIED="1534757298028" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_robots.coverage" NAME="01-分析robots协议 Coverage Results" MODIFIED="1534753477624" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/分析robots协议" />
    <SUITE FILE_PATH="coverage/PythonStudy$httpbin.coverage" NAME="httpbin Coverage Results" MODIFIED="1535533492020" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial" />
    <SUITE FILE_PATH="coverage/PythonStudy$05_Request_.coverage" NAME="05-发起一个Request请求-多个参数 Coverage Results" MODIFIED="1535017823063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/01-发起网络请求" />
    <SUITE FILE_PATH="coverage/PythonStudy$run__4_.coverage" NAME="run (4) Coverage Results" MODIFIED="1535606129742" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest" />
    <SUITE FILE_PATH="coverage/PythonStudy$11_.coverage" NAME="11.更新 Coverage Results" MODIFIED="1534923597885" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_if.coverage" NAME="01-if语句 Coverage Results" MODIFIED="1533722066979" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-5" />
    <SUITE FILE_PATH="coverage/PythonStudy$run.coverage" NAME="run Coverage Results" MODIFIED="1535533516605" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/03-downloader-middleware/scrapydownloadertest/scrapydownloadertest" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_render_png.coverage" NAME="01-render-png Coverage Results" MODIFIED="1535017406873" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/02-Splash/01-Splash-API调用" />
    <SUITE FILE_PATH="coverage/PythonStudy$01___1_.coverage" NAME="01-读取文件 (1) Coverage Results" MODIFIED="1534240955149" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-10/01-write" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestChromeDriver.coverage" NAME="TestChromeDriver Coverage Results" MODIFIED="1534472512221" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test" />
    <SUITE FILE_PATH="coverage/PythonStudy$api.coverage" NAME="api Coverage Results" MODIFIED="1535181097222" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/02-代理池维护" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_execute.coverage" NAME="02-execute接口 Coverage Results" MODIFIED="1535017497022" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/02-Splash/01-Splash-API调用" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_Selector.coverage" NAME="01-Selector的用法 Coverage Results" MODIFIED="1535519271573" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/02-Selector的用法" />
    <SUITE FILE_PATH="coverage/PythonStudy$07__.coverage" NAME="07.查询数据-条件 Coverage Results" MODIFIED="1534920730035" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_a_.coverage" NAME="01-获取所有a节点的超链接-歌手和歌名 Coverage Results" MODIFIED="1534821909577" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/06-正则/03-findall" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_POST_TimeOut.coverage" NAME="03-发送网络请求POST-TimeOut Coverage Results" MODIFIED="1534729639857" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_Splash_API.coverage" NAME="01-Splash-API调用 Coverage Results" MODIFIED="1535017299904" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/02-Splash" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_re.coverage" NAME="01-了解re库 Coverage Results" MODIFIED="1534817629080" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/06-正则" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_MongoDB.coverage" NAME="01-连接MongoDB Coverage Results" MODIFIED="1534910636022" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$07__2.coverage" NAME="07-函数参数-任意参数2 Coverage Results" MODIFIED="1533800182878" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-8" />
    <SUITE FILE_PATH="coverage/PythonStudy$10_SSL_HTTPS.coverage" NAME="10-SSL证书验证-HTTPS Coverage Results" MODIFIED="1534814695844" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests/高级用法" />
    <SUITE FILE_PATH="coverage/PythonStudy$10_.coverage" NAME="10-偏移 Coverage Results" MODIFIED="1534922815462" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$run__5_.coverage" NAME="run (5) Coverage Results" MODIFIED="1535616723516" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_write_json.coverage" NAME="01-write_json Coverage Results" MODIFIED="1534303702976" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-10/05-把json格式的数据存到文件" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_HTTPError.coverage" NAME="01-HTTPError Coverage Results" MODIFIED="1534748370250" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/处理异常" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_url.coverage" NAME="02-拼接一个完整的url Coverage Results" MODIFIED="1534749121007" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/解析链接" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_.coverage" NAME="04-插入数据 Coverage Results" MODIFIED="1534925440204" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$nfts.coverage" NAME="nfts Coverage Results" MODIFIED="1540535317723" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Demo" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_test.coverage" NAME="02-解析test网页 Coverage Results" MODIFIED="1534838485178" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/01-XPath的使用" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_.coverage" NAME="02-显式等待 Coverage Results" MODIFIED="1535012843823" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/06-延时等待" />
    <SUITE FILE_PATH="coverage/PythonStudy$08_Cookies.coverage" NAME="08-把网站的Cookies存到本地 Coverage Results" MODIFIED="1534746902370" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3" />
    <SUITE FILE_PATH="coverage/PythonStudy$robatparserexp.coverage" NAME="robatparserexp Coverage Results" MODIFIED="1534752148165" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/分析robots协议" />
    <SUITE FILE_PATH="coverage/PythonStudy$11__HTTPS.coverage" NAME="11-指定客户单的证书-HTTPS Coverage Results" MODIFIED="1534814874711" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests/高级用法" />
    <SUITE FILE_PATH="coverage/PythonStudy$09_Cookies.coverage" NAME="09-把网站的Cookies存到本地 Coverage Results" MODIFIED="1534747372331" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestScrapydAPI.coverage" NAME="TestScrapydAPI Coverage Results" MODIFIED="1534495468758" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test" />
    <SUITE FILE_PATH="coverage/PythonStudy$05__.coverage" NAME="05-函数参数-数列 Coverage Results" MODIFIED="1533799383857" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-8" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_readlines.coverage" NAME="03-readlines读取文件 Coverage Results" MODIFIED="1534240894253" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-10" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_selenium_PhantomJS.coverage" NAME="04-selenium-PhantomJS设置代理 Coverage Results" MODIFIED="1535096661157" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/01-设置道理伪装ip" />
    <SUITE FILE_PATH="coverage/PythonStudy$my_car__1_.coverage" NAME="my_car (1) Coverage Results" MODIFIED="1534236690815" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-9/model2" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_requests_.coverage" NAME="03-requests-设置代理 Coverage Results" MODIFIED="1535096257803" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/01-设置道理伪装ip" />
    <SUITE FILE_PATH="coverage/PythonStudy$05_.coverage" NAME="05-插入多条数据 Coverage Results" MODIFIED="1534919062142" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$02__.coverage" NAME="02-写文件-追加 Coverage Results" MODIFIED="1534298321339" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-10/02-write-file" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestBeautifulSoup.coverage" NAME="TestBeautifulSoup Coverage Results" MODIFIED="1534474127771" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_CSV.coverage" NAME="01-CSV文件写入 Coverage Results" MODIFIED="1534905722467" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/03-cvs" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_JavaScript.coverage" NAME="01-执行JavaScript Coverage Results" MODIFIED="1535011052896" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/04-执行JavaScript" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_XPath.coverage" NAME="01-XPath的基本使用 Coverage Results" MODIFIED="1534837626121" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/01-XPath的使用" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_POST.coverage" NAME="02-发送网络请求POST Coverage Results" MODIFIED="1534729316482" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_socks.coverage" NAME="02-测试设置代理socks Coverage Results" MODIFIED="1535096054587" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/01-设置道理伪装ip" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_while.coverage" NAME="02-while循环 Coverage Results" MODIFIED="1533787468599" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-7" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_Selenium.coverage" NAME="02-Selenium的使用 Coverage Results" MODIFIED="1535008549739" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面" />
    <SUITE FILE_PATH="coverage/PythonStudy$12_.coverage" NAME="12.删除 Coverage Results" MODIFIED="1534923820302" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$run__3_.coverage" NAME="run (3) Coverage Results" MODIFIED="1535595274886" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360" />
    <SUITE FILE_PATH="coverage/PythonStudy$13_Prepared_Request.coverage" NAME="13.Prepared-Request Coverage Results" MODIFIED="1534815953207" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests/高级用法" />
    <SUITE FILE_PATH="coverage/PythonStudy$requestqueue.coverage" NAME="requestqueue Coverage Results" MODIFIED="1535185347265" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/04-获取搜狗微信公众号的数据" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_Redis.coverage" NAME="01-链接Redis Coverage Results" MODIFIED="1534928286377" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/06-Redis" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_ZeroDivisionError.coverage" NAME="01-处理ZeroDivisionError异常 Coverage Results" MODIFIED="1534298717259" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-10/03-异常" />
    <SUITE FILE_PATH="coverage/PythonStudy$test.coverage" NAME="test Coverage Results" MODIFIED="1535622802373" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_json.coverage" NAME="01-读取json Coverage Results" MODIFIED="1534904552695" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储" />
    <SUITE FILE_PATH="coverage/PythonStudy$03__.coverage" NAME="03- 根据节点的文本查询元素 Coverage Results" MODIFIED="1534845370848" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/02-BeautifulSoups的使用/02-方法选择器" />
    <SUITE FILE_PATH="coverage/PythonStudy$09__.coverage" NAME="09-查询数据-推荐 Coverage Results" MODIFIED="1534909768494" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/04-mysql" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_test_.coverage" NAME="04-解析test网页-获取节点属性 Coverage Results" MODIFIED="1534839832701" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/01-XPath的使用" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_IFrame.coverage" NAME="04-切换IFrame Coverage Results" MODIFIED="1535012303444" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/05-获取节点信息" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_urlparseurl.coverage" NAME="01-urlparse解析url Coverage Results" MODIFIED="1534748967755" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/解析链接" />
    <SUITE FILE_PATH="coverage/PythonStudy$08_.coverage" NAME="08-计数 Coverage Results" MODIFIED="1534921494612" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_Redis.coverage" NAME="03-链接Redis Coverage Results" MODIFIED="1534925931238" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/06-Redis" />
    <SUITE FILE_PATH="coverage/PythonStudy$request.coverage" NAME="request Coverage Results" MODIFIED="1534735284066" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_Key.coverage" NAME="04-Key操作 Coverage Results" MODIFIED="1534926600113" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/06-Redis" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestTornado.coverage" NAME="TestTornado Coverage Results" MODIFIED="1534489580450" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test" />
    <SUITE FILE_PATH="coverage/PythonStudy$06__.coverage" NAME="06-提取文本-属性等信息 Coverage Results" MODIFIED="1534843929723" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/02-BeautifulSoups的使用/01-节点选择器" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestFlask.coverage" NAME="TestFlask Coverage Results" MODIFIED="1534489464323" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test" />
    <SUITE FILE_PATH="coverage/PythonStudy$08_session.coverage" NAME="08-会话维持session Coverage Results" MODIFIED="1534814076556" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests/高级用法" />
    <SUITE FILE_PATH="coverage/PythonStudy$index.coverage" NAME="index Coverage Results" MODIFIED="1535182347352" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/03-测试代理池-先要启动代理池" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_pandascsv.coverage" NAME="03-使用pandas读取csv Coverage Results" MODIFIED="1534906067386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/03-cvs" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestTesseract.coverage" NAME="TestTesseract Coverage Results" MODIFIED="1535079922315" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test-安装环境测试" />
    <SUITE FILE_PATH="coverage/PythonStudy$06_Cookies.coverage" NAME="06-获取和设置Cookies Coverage Results" MODIFIED="1534758839758" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_selenium_.coverage" NAME="04-selenium-设置代理 Coverage Results" MODIFIED="1535096450174" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/01-设置道理伪装ip" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_.coverage" NAME="01-测试设置代理 Coverage Results" MODIFIED="1535094604884" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/01-设置道理伪装ip" />
    <SUITE FILE_PATH="coverage/PythonStudy$alien_invasion.coverage" NAME="alien_invasion Coverage Results" MODIFIED="1534407246213" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/alien_invasion" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestTesseract2.coverage" NAME="TestTesseract2 Coverage Results" MODIFIED="1535078733976" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test-安装环境测试" />
    <SUITE FILE_PATH="coverage/PythonStudy$run__1_.coverage" NAME="run (1) Coverage Results" MODIFIED="1535534854832" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/03-downloader-middleware/scrapydownloadertest" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_li__1_.coverage" NAME="02-获取所有li节点的歌名 (1) Coverage Results" MODIFIED="1534827882841" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/06-正则/04-sub-replace" />
    <SUITE FILE_PATH="coverage/PythonStudy$07__3_.coverage" NAME="07-函数参数-任意参数3-关键字 Coverage Results" MODIFIED="1533801068938" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-8" />
    <SUITE FILE_PATH="coverage/PythonStudy$07_.coverage" NAME="07-删除数据 Coverage Results" MODIFIED="1534908774568" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/04-mysql" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_Request.coverage" NAME="04-发起一个Request请求 Coverage Results" MODIFIED="1534730323763" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3" />
    <SUITE FILE_PATH="coverage/PythonStudy$MaoYanSpider.coverage" NAME="MaoYanSpider Coverage Results" MODIFIED="1534836547840" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/06-正则/06-爬取猫眼的数据" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_Cookie.coverage" NAME="01-Cookie Coverage Results" MODIFIED="1535014940405" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/08-Cookies" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_helloworld.coverage" NAME="01-helloworld Coverage Results" MODIFIED="1533711872542" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-1" />
    <SUITE FILE_PATH="coverage/PythonStudy$02____.coverage" NAME="02- 操作列表(遍历数组) Coverage Results" MODIFIED="1533717697482" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-3" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_counts_world.coverage" NAME="01-counts-world Coverage Results" MODIFIED="1534301256041" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-10/04-计算文章的单词数" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_breakwhile.coverage" NAME="04-使用break退出while Coverage Results" MODIFIED="1533788454847" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-7" />
    <SUITE FILE_PATH="coverage/PythonStudy$04_json.coverage" NAME="04-保存json Coverage Results" MODIFIED="1534905004330" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储" />
    <SUITE FILE_PATH="coverage/PythonStudy$10_Cookie.coverage" NAME="10-加载本地的Cookie Coverage Results" MODIFIED="1534747637024" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_url.coverage" NAME="03-给url参数编码 Coverage Results" MODIFIED="1534750041875" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/解析链接" />
    <SUITE FILE_PATH="coverage/PythonStudy$05_test_.coverage" NAME="05-解析test网页-文本获取 Coverage Results" MODIFIED="1534840178019" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/01-XPath的使用" />
    <SUITE FILE_PATH="coverage/PythonStudy$my_car.coverage" NAME="my_car Coverage Results" MODIFIED="1534236105958" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-9/model" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_json.coverage" NAME="03-读取json Coverage Results" MODIFIED="1534904819114" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储" />
    <SUITE FILE_PATH="coverage/PythonStudy$09_SSL_HTTPS.coverage" NAME="09-SSL证书验证-HTTPS Coverage Results" MODIFIED="1534814341841" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests/高级用法" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_class.coverage" NAME="01-添加和删除class Coverage Results" MODIFIED="1534902433435" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/03-PyQuery的使用/04-节点操作" />
    <SUITE FILE_PATH="coverage/PythonStudy$06_.coverage" NAME="06.查询数据 Coverage Results" MODIFIED="1534925314362" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestPhantomJS.coverage" NAME="TestPhantomJS Coverage Results" MODIFIED="1534473284948" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_Redis.coverage" NAME="02-链接Redis Coverage Results" MODIFIED="1534925701153" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/06-Redis" />
    <SUITE FILE_PATH="coverage/PythonStudy$run__2_.coverage" NAME="run (2) Coverage Results" MODIFIED="1535533567994" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial" />
    <SUITE FILE_PATH="coverage/PythonStudy$07_cookies.coverage" NAME="07-设置cookies Coverage Results" MODIFIED="1534813499432" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/05-使用requests" />
    <SUITE FILE_PATH="coverage/PythonStudy$scheduler.coverage" NAME="scheduler Coverage Results" MODIFIED="1535186772545" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/02-代理池维护" />
    <SUITE FILE_PATH="coverage/PythonStudy$05_while.coverage" NAME="05-while拷贝数列 Coverage Results" MODIFIED="1533791516870" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-7" />
    <SUITE FILE_PATH="coverage/PythonStudy$demo.coverage" NAME="demo Coverage Results" MODIFIED="1534900091589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/02-BeautifulSoups的使用/01-节点选择器" />
    <SUITE FILE_PATH="coverage/PythonStudy$TestGeckoDriver.coverage" NAME="TestGeckoDriver Coverage Results" MODIFIED="1534471803187" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/Test" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_CSV.coverage" NAME="02-CSV文件读取 Coverage Results" MODIFIED="1534905847008" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/03-cvs" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_.coverage" NAME="03-访问页面 Coverage Results" MODIFIED="1535010334029" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面" />
    <SUITE FILE_PATH="coverage/PythonStudy$helloworld.coverage" NAME="helloworld Coverage Results" MODIFIED="1533702064284" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section1" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_test_.coverage" NAME="03-解析test网页-获取父节点 Coverage Results" MODIFIED="1534839729376" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section4-解析库使用/01-XPath的使用" />
    <SUITE FILE_PATH="coverage/PythonStudy$MaoYanSpider__1_.coverage" NAME="MaoYanSpider (1) Coverage Results" MODIFIED="1534837401836" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/06-正则/06-爬取猫眼的数据" />
    <SUITE FILE_PATH="coverage/PythonStudy$07_Cookies.coverage" NAME="07-获取网站的Cookies Coverage Results" MODIFIED="1534746605873" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_read_json.coverage" NAME="02-read_json Coverage Results" MODIFIED="1534303886550" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-10/05-把json格式的数据存到文件" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_li.coverage" NAME="02-获取所有li节点的歌名 Coverage Results" MODIFIED="1534822619377" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section3/06-正则/03-findall" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_execute.coverage" NAME="03-execute接口 Coverage Results" MODIFIED="1535017543898" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/02-Splash/01-Splash-API调用" />
    <SUITE FILE_PATH="coverage/PythonStudy$03_while.coverage" NAME="03-使用标签推出while Coverage Results" MODIFIED="1533787682580" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-7" />
    <SUITE FILE_PATH="coverage/PythonStudy$index__1_.coverage" NAME="index (1) Coverage Results" MODIFIED="1535085647331" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section8-验证码识别/02-图型识别" />
    <SUITE FILE_PATH="coverage/PythonStudy$02_random.coverage" NAME="02-random Coverage Results" MODIFIED="1534238930795" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/section-9/python标准库" />
    <SUITE FILE_PATH="coverage/PythonStudy$09_.coverage" NAME="09-排序 Coverage Results" MODIFIED="1534922588550" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/05-MongoDB" />
    <SUITE FILE_PATH="coverage/PythonStudy$spider.coverage" NAME="spider Coverage Results" MODIFIED="1535186879102" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/04-获取搜狗微信公众号的数据" />
    <SUITE FILE_PATH="coverage/PythonStudy$alien.coverage" NAME="alien Coverage Results" MODIFIED="1534388276732" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/book/alien_invasion" />
    <SUITE FILE_PATH="coverage/PythonStudy$01_TXT.coverage" NAME="01-TXT文本存储 Coverage Results" MODIFIED="1534904227566" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储" />
  </component>
  <component name="FUSProjectUsageTrigger">
    <session id="-1627443675">
      <usages-collector id="statistics.lifecycle.project">
        <counts>
          <entry key="project.closed" value="9" />
          <entry key="project.open.time.0" value="1" />
          <entry key="project.open.time.16" value="1" />
          <entry key="project.open.time.17" value="1" />
          <entry key="project.open.time.18" value="1" />
          <entry key="project.open.time.31" value="1" />
          <entry key="project.open.time.41" value="2" />
          <entry key="project.open.time.42" value="1" />
          <entry key="project.open.time.44" value="1" />
          <entry key="project.open.time.6" value="1" />
          <entry key="project.open.time.7" value="1" />
          <entry key="project.open.time.9" value="1" />
          <entry key="project.opened" value="12" />
        </counts>
      </usages-collector>
      <usages-collector id="statistics.file.extensions.open">
        <counts>
          <entry key="Dockerfile" value="1" />
          <entry key="bmp" value="1" />
          <entry key="cfg" value="2" />
          <entry key="csv" value="7" />
          <entry key="html" value="7" />
          <entry key="ico" value="1" />
          <entry key="jl" value="3" />
          <entry key="jpeg" value="7" />
          <entry key="jpg" value="11" />
          <entry key="js" value="6" />
          <entry key="json" value="25" />
          <entry key="log" value="1" />
          <entry key="md" value="25" />
          <entry key="png" value="2" />
          <entry key="py" value="768" />
          <entry key="rnc" value="1" />
          <entry key="txt" value="26" />
          <entry key="wxml" value="1" />
        </counts>
      </usages-collector>
      <usages-collector id="statistics.file.types.open">
        <counts>
          <entry key="Dockerfile" value="1" />
          <entry key="HTML" value="7" />
          <entry key="Image" value="22" />
          <entry key="Ini" value="2" />
          <entry key="JSON" value="25" />
          <entry key="JavaScript" value="6" />
          <entry key="Markdown" value="25" />
          <entry key="PLAIN_TEXT" value="38" />
          <entry key="Python" value="768" />
          <entry key="RNG Compact" value="1" />
        </counts>
      </usages-collector>
      <usages-collector id="statistics.file.extensions.edit">
        <counts>
          <entry key="Dockerfile" value="168" />
          <entry key="cfg" value="37" />
          <entry key="dummy" value="82" />
          <entry key="html" value="217" />
          <entry key="jl" value="31" />
          <entry key="js" value="140" />
          <entry key="json" value="528" />
          <entry key="md" value="1371" />
          <entry key="py" value="54905" />
          <entry key="txt" value="83" />
        </counts>
      </usages-collector>
      <usages-collector id="statistics.file.types.edit">
        <counts>
          <entry key="Dockerfile" value="168" />
          <entry key="HTML" value="217" />
          <entry key="Ini" value="37" />
          <entry key="JSON" value="528" />
          <entry key="JavaScript" value="140" />
          <entry key="Markdown" value="1366" />
          <entry key="PLAIN_TEXT" value="196" />
          <entry key="Python" value="54894" />
          <entry key="RegExp" value="8" />
          <entry key="SQL" value="8" />
        </counts>
      </usages-collector>
    </session>
  </component>
  <component name="FileEditorManager">
    <leaf />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="HTML File" />
        <option value="Python Script" />
      </list>
    </option>
  </component>
  <component name="FindInProjectRecents">
    <findStrings>
      <find>url</find>
      <find>data</find>
      <find>write</find>
      <find>kwargs</find>
    </findStrings>
    <replaceStrings>
      <replace />
    </replaceStrings>
    <dirStrings>
      <dir>$PROJECT_DIR$/book/section-10/05-把json格式的数据存到文件</dir>
    </dirStrings>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
  </component>
  <component name="IdeDocumentHistory">
    <option name="CHANGED_PATHS">
      <list>
        <option value="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/04-获取搜狗微信公众号的数据/run.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/02-代理池维护/run.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/04-获取搜狗微信公众号的数据/config.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/02-代理池维护/setting.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/04-获取搜狗微信公众号的数据/spider.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-pyspider的基本使用.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial/tutorial/items.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial/quotes.json" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial/tutorial/pipelines.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial/tutorial/spiders/quotes.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/02-Selector的用法/01-Selector的用法.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/02-Selector的用法/demo.html" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/02-Selector的用法/02-Scrapy-Shell.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial/tutorial/settings.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/03-downloader-middleware/scrapydownloadertest/run.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial/run.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/03-downloader-middleware/scrapydownloadertest/scrapydownloadertest/settings.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/03-downloader-middleware/scrapydownloadertest/scrapydownloadertest/spiders/httpbin.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/03-downloader-middleware/scrapydownloadertest/scrapydownloadertest/middlewares.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360/scrapy.cfg" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360/run.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360/images360/items.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360/images360/spiders/images.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360/images360/middlewares.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360/images360/pipelines.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360/images360/settings.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/run.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/items.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/spiders/taobao.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/pipelines.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/settings.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/items.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/itemloader.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/spiders/china.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/run.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/AppRun.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/rules.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/spiders/universal.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/urls.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/config/china.json" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/AppRun.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/utils.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/middlewares.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/test.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/spiders/quotes.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/requirements.txt" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/settings.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/Dockerfile" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/spiders/weibocn.py" />
        <option value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/middlewares.py" />
        <option value="$PROJECT_DIR$/Demo/nfts.py" />
      </list>
    </option>
  </component>
  <component name="JsBuildToolGruntFileManager" detection-done="true" sorting="DEFINITION_ORDER" />
  <component name="JsBuildToolPackageJson" detection-done="true" sorting="DEFINITION_ORDER" />
  <component name="JsGulpfileManager">
    <detection-done>true</detection-done>
    <sorting>DEFINITION_ORDER</sorting>
  </component>
  <component name="ProjectFrameBounds">
    <option name="y" value="23" />
    <option name="width" value="1920" />
    <option name="height" value="977" />
  </component>
  <component name="ProjectLevelVcsManager" settingsEditedManually="true" />
  <component name="ProjectView">
    <navigator proportions="" version="1">
      <foldersAlwaysOnTop value="true" />
    </navigator>
    <panes>
      <pane id="ProjectPane">
        <subPane>
          <expand>
            <path>
              <item name="PythonStudy" type="b2602c69:ProjectViewProjectNode" />
              <item name="PythonStudy" type="462c0819:PsiDirectoryNode" />
            </path>
          </expand>
          <select />
        </subPane>
      </pane>
      <pane id="Scope" />
    </panes>
  </component>
  <component name="PropertiesComponent">
    <property name="DefaultHtmlFileTemplate" value="HTML File" />
    <property name="SearchEverywhereHistoryKey" value="&#9;FILE&#9;file:///Users/android-school/Python/PythonStudy/Python3网络爬虫/section3/readme/readme.md" />
    <property name="WebServerToolWindowFactoryState" value="false" />
    <property name="last_opened_file_path" value="$PROJECT_DIR$" />
    <property name="nodejs_package_manager_path" value="npm" />
    <property name="run.code.analysis.last.selected.profile" value="pProject Default" />
    <property name="settings.editor.selected.configurable" value="com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable" />
  </component>
  <component name="RecentsManager">
    <key name="CopyFile.RECENT_KEYS">
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal" />
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest" />
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial" />
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/03-downloader-middleware/scrapydownloadertest/scrapydownloadertest" />
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section9-代理的使用/02-代理池维护" />
    </key>
    <key name="MoveFile.RECENT_KEYS">
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal" />
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section12-pyspider框架的使用" />
      <recent name="$PROJECT_DIR$/Python3网络爬虫/Test-安装环境测试" />
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/02-Splash/01-Splash-API调用" />
      <recent name="$PROJECT_DIR$/Python3网络爬虫/section7-动态渲染页面/01-Selenium" />
    </key>
  </component>
  <component name="RunDashboard">
    <option name="ruleStates">
      <list>
        <RuleState>
          <option name="name" value="ConfigurationTypeDashboardGroupingRule" />
        </RuleState>
        <RuleState>
          <option name="name" value="StatusDashboardGroupingRule" />
        </RuleState>
      </list>
    </option>
  </component>
  <component name="RunManager" selected="Python.nfts">
    <configuration name="nfts" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="PythonStudy" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Demo" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Demo/nfts.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run (3)" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="PythonStudy" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/images360/run.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run (4)" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="PythonStudy" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/run.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run (5)" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="PythonStudy" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/run.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="test" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="PythonStudy" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/test.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <list>
      <item itemvalue="Python.run (3)" />
      <item itemvalue="Python.run (4)" />
      <item itemvalue="Python.run (5)" />
      <item itemvalue="Python.test" />
      <item itemvalue="Python.nfts" />
    </list>
    <recent_temporary>
      <list>
        <item itemvalue="Python.nfts" />
        <item itemvalue="Python.test" />
        <item itemvalue="Python.run (5)" />
        <item itemvalue="Python.run (4)" />
        <item itemvalue="Python.run (3)" />
      </list>
    </recent_temporary>
  </component>
  <component name="SvnConfiguration">
    <configuration />
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="359a81d1-a1e5-4eac-91a2-6b13a25942df" name="Default Changelist" comment="" />
      <created>1533699639194</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1533699639194</updated>
    </task>
    <servers />
  </component>
  <component name="ToolWindowManager">
    <frame x="0" y="23" width="1920" height="977" extended-state="0" />
    <layout>
      <window_info active="true" content_ui="combo" id="Project" order="0" visible="true" weight="0.1682641" />
      <window_info id="Structure" order="1" side_tool="true" weight="0.25" />
      <window_info id="Favorites" order="2" side_tool="true" />
      <window_info anchor="bottom" id="Message" order="0" />
      <window_info anchor="bottom" id="Find" order="1" sideWeight="0.49946752" weight="0.32881355" />
      <window_info anchor="bottom" id="Run" order="2" sideWeight="0.8482428" weight="0.26892656" />
      <window_info anchor="bottom" id="Debug" order="3" sideWeight="0.84717786" weight="0.58348626" />
      <window_info anchor="bottom" id="Cvs" order="4" weight="0.25" />
      <window_info anchor="bottom" id="Inspection" order="5" weight="0.4" />
      <window_info anchor="bottom" id="TODO" order="6" />
      <window_info anchor="bottom" id="Docker" order="7" show_stripe_button="false" />
      <window_info anchor="bottom" id="Version Control" order="8" />
      <window_info anchor="bottom" id="Database Changes" order="9" show_stripe_button="false" />
      <window_info anchor="bottom" id="Event Log" order="10" sideWeight="0.1517572" side_tool="true" weight="0.3898305" />
      <window_info anchor="bottom" id="Terminal" order="11" weight="0.24971752" />
      <window_info anchor="bottom" id="Python Console" order="12" />
      <window_info anchor="bottom" id="Concurrent Activities Diagram" order="13" weight="0.52090394" />
      <window_info anchor="right" id="Commander" internal_type="SLIDING" order="0" type="SLIDING" weight="0.4" />
      <window_info anchor="right" id="Ant Build" order="1" weight="0.25" />
      <window_info anchor="right" content_ui="combo" id="Hierarchy" order="2" weight="0.25" />
      <window_info anchor="right" id="SciView" order="3" />
      <window_info anchor="right" id="Database" order="4" />
    </layout>
    <layout-to-restore>
      <window_info content_ui="combo" id="Project" order="0" visible="true" weight="0.19683544" />
      <window_info id="Structure" order="1" side_tool="true" weight="0.25" />
      <window_info id="Favorites" order="2" side_tool="true" />
      <window_info anchor="bottom" id="Message" order="0" />
      <window_info anchor="bottom" id="Find" order="1" sideWeight="0.49946752" weight="0.32905295" />
      <window_info anchor="bottom" id="Run" order="2" sideWeight="0.8482428" weight="0.23311259" />
      <window_info anchor="bottom" id="Debug" order="3" sideWeight="0.84717786" weight="0.32542372" />
      <window_info anchor="bottom" id="Cvs" order="4" weight="0.25" />
      <window_info anchor="bottom" id="Inspection" order="5" weight="0.4" />
      <window_info anchor="bottom" id="TODO" order="6" />
      <window_info anchor="bottom" id="Docker" order="7" show_stripe_button="false" />
      <window_info anchor="bottom" id="Version Control" order="8" />
      <window_info anchor="bottom" id="Database Changes" order="9" show_stripe_button="false" />
      <window_info anchor="bottom" id="Event Log" order="10" sideWeight="0.1517572" side_tool="true" weight="0.3898305" />
      <window_info active="true" anchor="bottom" id="Terminal" order="11" visible="true" weight="0.41854304" />
      <window_info anchor="bottom" id="Python Console" order="12" />
      <window_info anchor="bottom" id="Concurrent Activities Diagram" order="13" weight="0.52090394" />
      <window_info anchor="right" id="Commander" internal_type="SLIDING" order="0" type="SLIDING" weight="0.4" />
      <window_info anchor="right" id="Ant Build" order="1" weight="0.25" />
      <window_info anchor="right" content_ui="combo" id="Hierarchy" order="2" weight="0.25" />
      <window_info anchor="right" id="SciView" order="3" />
      <window_info anchor="right" id="Database" order="4" />
    </layout-to-restore>
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="1" />
  </component>
  <component name="VcsContentAnnotationSettings">
    <option name="myLimit" value="2678400000" />
  </component>
  <component name="XDebuggerManager">
    <breakpoint-manager>
      <breakpoints>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py</url>
          <line>583</line>
          <option name="timeStamp" value="2" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py</url>
          <line>508</line>
          <option name="timeStamp" value="3" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py</url>
          <line>333</line>
          <option name="timeStamp" value="4" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py</url>
          <line>315</line>
          <option name="timeStamp" value="5" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py</url>
          <line>524</line>
          <option name="timeStamp" value="6" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py</url>
          <line>1279</line>
          <option name="timeStamp" value="12" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py</url>
          <line>1285</line>
          <option name="timeStamp" value="13" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py</url>
          <line>1300</line>
          <option name="timeStamp" value="14" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py</url>
          <line>1233</line>
          <option name="timeStamp" value="16" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py</url>
          <line>1058</line>
          <option name="timeStamp" value="20" />
        </line-breakpoint>
      </breakpoints>
      <default-breakpoints>
        <breakpoint type="python-exception">
          <properties notifyOnTerminate="true" exception="BaseException">
            <option name="notifyOnTerminate" value="true" />
          </properties>
        </breakpoint>
      </default-breakpoints>
    </breakpoint-manager>
    <watches-manager>
      <configuration name="PythonConfigurationType">
        <watch expression="req" />
      </configuration>
    </watches-manager>
  </component>
  <component name="editorHistoryManager">
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/settings.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="229">
          <caret line="79" column="53" lean-forward="true" selection-start-line="79" selection-start-column="53" selection-end-line="79" selection-end-column="53" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/06-正则/01-match/02-匹配目标数据.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-12" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/pipelines.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="349">
          <caret line="29" column="31" selection-start-line="29" selection-start-column="21" selection-end-line="29" selection-end-column="31" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/06-正则/01-match/03-通用匹配符号.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/06-正则/01-match/01-了解re库.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/06-正则/02-search/01-扫描整个字符串.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="257">
          <caret line="11" column="33" selection-start-line="11" selection-start-column="33" selection-end-line="11" selection-end-column="33" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/06-正则/04-sub-replace/01-所有数字都去掉.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/02-Selector的用法/02-Scrapy-Shell.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="1368">
          <caret line="57" lean-forward="true" selection-start-line="57" selection-end-line="57" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/itemloader.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="216">
          <caret line="9" column="1" selection-start-line="9" selection-start-column="1" selection-end-line="10" selection-end-column="53" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/settings.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="340">
          <caret line="16" lean-forward="true" selection-start-line="16" selection-end-line="16" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/run.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/rules.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="192">
          <caret line="8" column="10" lean-forward="true" selection-start-line="8" selection-start-column="10" selection-end-line="8" selection-end-column="10" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/02-json/02-读取json.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-130" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/02-json/03-读取json.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="278">
          <caret line="12" lean-forward="true" selection-start-line="12" selection-end-line="12" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section5-数据的存储/01-文件存储/02-json/04-保存json.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="288">
          <caret line="12" column="56" lean-forward="true" selection-start-line="12" selection-start-column="56" selection-end-line="12" selection-end-column="56" />
        </state>
      </provider>
    </entry>
    <entry file="file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/__init__.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-711">
          <caret line="299" column="73" selection-start-line="299" selection-start-column="71" selection-end-line="299" selection-end-column="73" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/config/item.json" />
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/items.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="239">
          <caret line="10" column="14" selection-start-line="10" selection-start-column="6" selection-end-line="10" selection-end-column="14" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/spiders/universal.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="272">
          <caret line="23" column="101" selection-start-line="23" selection-start-column="97" selection-end-line="23" selection-end-column="101" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/AppRun.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="193">
          <caret line="12" column="19" lean-forward="true" selection-start-line="12" selection-start-column="19" selection-end-line="12" selection-end-column="19" />
        </state>
      </provider>
    </entry>
    <entry file="file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="269">
          <caret line="1885" column="45" lean-forward="true" selection-start-line="1885" selection-start-column="45" selection-end-line="1885" selection-end-column="45" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/items.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="63">
          <caret line="12" column="19" lean-forward="true" selection-start-line="12" selection-start-column="19" selection-end-line="12" selection-end-column="19" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/utils.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="144">
          <caret line="6" column="36" selection-start-line="6" selection-start-column="36" selection-end-line="6" selection-end-column="36" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/urls.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="48">
          <caret line="2" column="75" lean-forward="true" selection-start-line="2" selection-start-column="75" selection-end-line="2" selection-end-column="75" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/spiders/china.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="264">
          <caret line="11" column="29" lean-forward="true" selection-start-line="11" selection-start-column="29" selection-end-line="11" selection-end-column="29" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/spiders/taobao.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="228">
          <caret line="15" column="52" lean-forward="true" selection-start-line="15" selection-start-column="52" selection-end-line="15" selection-end-column="52" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/test.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/05-Scrapy-Selenium/scrapyseleniumtest/scrapyseleniumtest/middlewares.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="192">
          <caret line="46" column="40" lean-forward="true" selection-start-line="46" selection-start-column="40" selection-end-line="46" selection-end-column="40" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/config/china.json">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="24">
          <caret line="21" column="11" selection-start-line="21" selection-start-column="11" selection-end-line="21" selection-end-column="11" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/06-Scrapy通用爬虫/scrapyuinversal/scrapyuinversal/pipelines.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="240">
          <caret line="10" column="19" lean-forward="true" selection-start-line="10" selection-start-column="19" selection-end-line="10" selection-end-column="19" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/items.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="208">
          <caret line="9" lean-forward="true" selection-start-line="9" selection-end-line="9" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/middlewares.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-1068" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.csv" />
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.jl" />
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/quotes.json" />
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/01-Scrapy入门/tutorial/tutorial/spiders/quotes.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="99">
          <caret line="62" column="28" selection-start-line="62" selection-start-column="28" selection-end-line="62" selection-end-column="28" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/spiders/quotes.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="401">
          <caret line="27" column="6" lean-forward="true" selection-start-line="27" selection-start-column="6" selection-end-line="27" selection-end-column="6" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/requirements.txt">
      <provider selected="true" editor-type-id="text-editor">
        <state>
          <caret column="13" lean-forward="true" selection-start-column="13" selection-end-column="13" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/pipelines.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="485">
          <caret line="38" column="35" lean-forward="true" selection-start-line="38" selection-start-column="35" selection-end-line="38" selection-end-column="35" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/tutorial/settings.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-95">
          <caret line="71" lean-forward="true" selection-start-line="71" selection-end-line="71" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/ScrapyTutorial/Dockerfile">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="288">
          <caret line="12" column="18" selection-start-line="12" selection-start-column="18" selection-end-line="12" selection-end-column="18" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/05-使用requests/高级用法/07-设置cookies.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-234" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section3-基本库使用/05-使用requests/高级用法/08-会话维持session.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="423">
          <caret line="19" column="41" lean-forward="true" selection-start-line="19" selection-start-column="41" selection-end-line="19" selection-end-column="41" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/README.md">
      <provider selected="true" editor-type-id="split-provider[text-editor;markdown-preview-editor]">
        <state split_layout="SPLIT">
          <first_editor relative-caret-position="48">
            <caret line="2" column="25" lean-forward="true" selection-start-line="2" selection-start-column="25" selection-end-line="2" selection-end-column="25" />
          </first_editor>
          <second_editor />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/pipelines.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="259">
          <caret line="37" column="19" lean-forward="true" selection-start-line="37" selection-start-column="19" selection-end-line="37" selection-end-column="19" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/items.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-172" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/middlewares.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="197">
          <caret line="12" column="24" lean-forward="true" selection-start-line="12" selection-start-column="24" selection-end-line="12" selection-end-column="24" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Python3网络爬虫/section13-Scrapy框架的使用/07-爬取新浪微博/Weibo/weibo/spiders/weibocn.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="462">
          <caret line="138" column="23" selection-start-line="138" selection-start-column="23" selection-end-line="138" selection-end-column="23" />
        </state>
      </provider>
    </entry>
    <entry file="file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scrapy/http/request/__init__.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="384">
          <caret line="16" column="22" selection-start-line="16" selection-start-column="22" selection-end-line="16" selection-end-column="22" />
        </state>
      </provider>
    </entry>
    <entry file="file:///Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scrapy/utils/trackref.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-179">
          <caret line="32" column="18" selection-start-line="32" selection-start-column="15" selection-end-line="32" selection-end-column="18" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Demo/nfts.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
  </component>
</project>